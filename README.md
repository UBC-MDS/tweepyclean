# tweepyclean

![](https://github.com/syadk/tweepyclean/workflows/build/badge.svg) [![codecov](https://codecov.io/gh/syadk/tweepyclean/branch/main/graph/badge.svg)](https://codecov.io/gh/syadk/tweepyclean) ![Release](https://github.com/syadk/tweepyclean/workflows/Release/badge.svg) [![Documentation Status](https://readthedocs.org/projects/tweepyclean/badge/?version=latest)](https://tweepyclean.readthedocs.io/en/latest/?badge=latest)

tweepyclean is a Python package built to act as a processor of data generated by the existing [Tweepy package](https://www.tweepy.org/) that can produce clean data frames, summarize data, and generate new features.

Our package aims to add additional resources for users of the already existing Tweepy package. Tweepy is a package built around Twitter's API and is used to scrape tweet information from their servers. Our package creates functionality which enables users to process the raw data from Tweepy into a more understandable format by extracting and organizing the contents of tweets for a user. tweepyclean is specifically built to be used in analysis of a specific user's timeline (generated using tweepy's api.user\_timeline function). Users can easily visualize average engagement based on time of day posted, see basic summary statistics of word contents and sentiment analysis of tweets and have a processed dataset that can be used in a wide variety of machine learning models.

## Installation

``` {.bash}
$ pip install -i https://test.pypi.org/simple/ tweepyclean
```

## Features

-   TODO

## Dependencies

-   TODO

## Usage

**Functions**

`raw_df(tweets)` :Creates a dataframe with labeled columns from a tweepy.cursor.ItemIterator object. The dataframe will have labeled columns containing the id, created\_at, full\_text, favorite\_count, retweet\_count, retweeted, entities, in\_reply\_to\_user\_id, and source columns from the iterator

`clean_tweets(tweets, handle = "", text_only = True, emojis = True, hashtags = True, sentiment = True, flesch_readability = True, media_links = True, proportion_of_avg_retweets = True, proportion_of_avg_hearts = True)`: Creates new columns based on the data in the pandas.dataframe generated by raw\_df() and returns a new dataframe. Can generate the following columns.

-   handle: Adds a column containing the a specified twitter handle.

-   text\_only: Adds a column of the tweet text containing no emojis, links, hashtags, or mentions.

-   emojis: Adds a column of the extracted emojis from tweet text and places them in their own column

-   hashtags: Add a column of the extracted hashtags from tweet text

-   sentiment: add a column containing the nltk.sentiment.vader SentimentIntensityAnalyzer sentiment score for each tweet

-   flesch\_readability: Adds a column containing the textstat flesch readability score (default is True)

-   media\_links: Adds a column containing links to photo or video attached to a tweet

-   proportion\_of\_avg\_retweets: Adds a column containing a proportion value of how many retweets a tweet received compared to the account average.

-   proportion\_of\_avg\_hearts: Adds a column containing a proportion value of how many hearts a tweet received compared to the account average

`engagement_by_hour(tweets)` : Creates an Altair line chart of total number of likes and retweets received by hour of tweet posted.

`tweet_words(clean_dataframe, top_n)` : Returns a pandas.DataFrame of the most common words and counts from a list of tweets.

`sentiment_total(data, lexicon)`: Takes unaggregated tweet data and summarizes the number of tweeted words associated with particular emotional sentiments. Returns an Altair linechart.

## tweepyclean's Place in the Python Ecosystem

tweepyclean provides functionality that is the first of its kind. Working with tweepy data has always required extensive data processing in order to produce a clean dataframe with useful features. By using tweepyclean it is easy and straightforward to extract the data hidden within the features that tweepy already scrapes, while also allowing users to optionally apply various forms of statistical analysis and language processing tools (such as sentiment analysis) to the data. This is combined with streamlined summary statistics methods that can quickly and effortlessly produce figures and tables of various different factors in your tweepy data. This allows users to easily understand and analyze information about a twitter user's timeline. Specifically, examining an accounts engagement, most common words, and emotional sentiment can each be done with a single function.

## Documentation

The official documentation is hosted on Read the Docs: <https://tweepyclean.readthedocs.io/en/latest/>

## Contributors

We welcome and recognize all contributions. You can see a list of current contributors in the [contributors tab]. This repository is currently maintained by [@nashmakh], [@calsvein], [@MattTPin], [@syak].

### Credits

This package was created with Cookiecutter and the UBC-MDS/cookiecutter-ubc-mds project template, modified from the [pyOpenSci/cookiecutter-pyopensci](https://github.com/pyOpenSci/cookiecutter-pyopensci) project template and the [audreyr/cookiecutter-pypackage](https://github.com/audreyr/cookiecutter-pypackage).
